{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 82.681564 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 80.446927 percent accurate\n",
      "Random Forests is 84.916201 percent accurate\n",
      "Accuracy score in each iteration: [0.770949720670391, 0.7821229050279329, 0.8212290502793296, 0.7821229050279329, 0.7877094972067039]\n",
      "K-Fold Score: 0.788826815642458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 75.977654 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 82.122905 percent accurate\n",
      "Random Forests is 86.033520 percent accurate\n",
      "Accuracy score in each iteration: [0.6983240223463687, 0.6703910614525139, 0.7206703910614525, 0.7430167597765364, 0.7486033519553073]\n",
      "K-Fold Score: 0.7162011173184357\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 35.754190 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 82.122905 percent accurate\n",
      "Random Forests is 84.916201 percent accurate\n",
      "Accuracy score in each iteration: [0.8547486033519553, 0.8156424581005587, 0.7932960893854749, 0.7597765363128491, 0.770949720670391]\n",
      "K-Fold Score: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 72.625698 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 81.564246 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7877094972067039, 0.776536312849162, 0.6424581005586593, 0.7653631284916201, 0.8268156424581006]\n",
      "K-Fold Score: 0.7597765363128491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 75.418994 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 79.329609 percent accurate\n",
      "Random Forests is 83.798883 percent accurate\n",
      "Accuracy score in each iteration: [0.6536312849162011, 0.6480446927374302, 0.7150837988826816, 0.6815642458100558, 0.6983240223463687]\n",
      "K-Fold Score: 0.6793296089385474\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 82.681564 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 80.446927 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7877094972067039, 0.770949720670391, 0.7486033519553073, 0.7877094972067039, 0.7877094972067039]\n",
      "K-Fold Score: 0.776536312849162\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 78.212291 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 81.564246 percent accurate\n",
      "Random Forests is 86.033520 percent accurate\n",
      "Accuracy score in each iteration: [0.7988826815642458, 0.7932960893854749, 0.7988826815642458, 0.8100558659217877, 0.8044692737430168]\n",
      "K-Fold Score: 0.8011173184357542\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 63.128492 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 80.446927 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7597765363128491, 0.8156424581005587, 0.8324022346368715, 0.8491620111731844, 0.8100558659217877]\n",
      "StratifiedKFold Score: 0.8134078212290502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 67.597765 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 80.446927 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7039106145251397, 0.659217877094972, 0.7486033519553073, 0.7206703910614525, 0.7486033519553073]\n",
      "StratifiedKFold Score: 0.7162011173184358\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 78.212291 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 78.770950 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7262569832402235, 0.7430167597765364, 0.7430167597765364, 0.7430167597765364, 0.6815642458100558]\n",
      "StratifiedKFold Score: 0.7273743016759776\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 73.184358 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 81.005587 percent accurate\n",
      "Random Forests is 84.357542 percent accurate\n",
      "Accuracy score in each iteration: [0.7988826815642458, 0.7932960893854749, 0.8324022346368715, 0.8324022346368715, 0.7262569832402235]\n",
      "StratifiedKFold Score: 0.7966480446927374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 77.653631 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 79.329609 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7988826815642458, 0.7486033519553073, 0.7653631284916201, 0.7541899441340782, 0.7988826815642458]\n",
      "StratifiedKFold Score: 0.7731843575418995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 83.240223 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 79.888268 percent accurate\n",
      "Random Forests is 85.474860 percent accurate\n",
      "Accuracy score in each iteration: [0.7094972067039106, 0.7597765363128491, 0.8044692737430168, 0.7877094972067039, 0.8100558659217877]\n",
      "StratifiedKFold Score: 0.7743016759776535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 82.681564 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 79.329609 percent accurate\n",
      "Random Forests is 86.033520 percent accurate\n",
      "Accuracy score in each iteration: [0.7374301675977654, 0.7374301675977654, 0.7039106145251397, 0.6312849162011173, 0.664804469273743]\n",
      "StratifiedKFold Score: 0.6949720670391061\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 78.212291 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 80.446927 percent accurate\n",
      "Random Forests is 84.916201 percent accurate\n",
      "Accuracy score in each iteration: [0.776536312849162, 0.770949720670391, 0.7430167597765364, 0.7597765363128491, 0.7988826815642458]\n",
      "StratifiedKFold Score: 0.7698324022346369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 83.798883 percent accurate\n",
      "KNN is 75.977654 percent accurate\n",
      "Naive Bayes is 82.681564 percent accurate\n",
      "Linear SVMs is 83.798883 percent accurate\n",
      "Non Linear SVMs is 74.301676 percent accurate\n",
      "Decision Trees is 81.005587 percent accurate\n",
      "Random Forests is 83.798883 percent accurate\n",
      "Accuracy score in each iteration: [0.8268156424581006, 0.8212290502793296, 0.7988826815642458, 0.7932960893854749, 0.8100558659217877]\n",
      "StratifiedKFold Score: 0.8100558659217876\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv('train.csv')\n",
    "titanic_cat = titanic.select_dtypes(object)\n",
    "titanic_num = titanic.select_dtypes(np.number)\n",
    "titanic_cat.drop(['Name','Ticket'], axis=1, inplace=True)\n",
    "titanic_cat.Cabin.fillna(titanic_cat.Cabin.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.Embarked.fillna(titanic_cat.Embarked.value_counts().idxmax(), inplace=True)\n",
    "titanic_cat.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_cat = titanic_cat.apply(le.fit_transform)\n",
    "titanic_cat.head()\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.Age.fillna(titanic_num.Age.mean(), inplace=True)\n",
    "titanic_num.isna().sum()\n",
    "titanic_num.drop(['PassengerId'], axis=1, inplace=True)\n",
    "titanic_num.head()\n",
    "titanic_final = pd.concat([titanic_cat,titanic_num],axis=1)\n",
    "titanic_final.head()\n",
    "X = titanic_final.drop(['Survived'], axis=1)\n",
    "Y = titanic_final['Survived']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifiedKFold Score: {}\".format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d670acca4543613bc71420ba3b408e5826bdc54b760740e8ce26eaf03bb45f97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
