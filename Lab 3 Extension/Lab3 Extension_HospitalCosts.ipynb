{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 51.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 50.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.43, 0.45, 0.41, 0.45, 0.44]\n",
      "K-Fold Score: 0.43600000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 51.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 49.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.46, 0.42, 0.38, 0.51, 0.22]\n",
      "K-Fold Score: 0.398\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 49.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.02, 0.01, 0.0, 0.01, 0.03]\n",
      "K-Fold Score: 0.014000000000000002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.4, 0.42, 0.48, 0.37, 0.4]\n",
      "K-Fold Score: 0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.43, 0.39, 0.48, 0.43, 0.42]\n",
      "K-Fold Score: 0.43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 53.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.46, 0.4, 0.39, 0.44, 0.39]\n",
      "K-Fold Score: 0.41600000000000004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 51.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 49.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.45, 0.48, 0.39, 0.44, 0.49]\n",
      "K-Fold Score: 0.45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.4, 0.5, 0.53, 0.44, 0.52]\n",
      "StratifedKFold Score: 0.47800000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.45, 0.45, 0.43, 0.44, 0.4]\n",
      "StratifedKFold Score: 0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 51.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 49.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.14, 0.02, 0.0, 0.01, 0.01]\n",
      "StratifedKFold Score: 0.036000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 51.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 51.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.4, 0.44, 0.54, 0.46, 0.48]\n",
      "StratifedKFold Score: 0.4640000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 52.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.46, 0.53, 0.4, 0.45, 0.46]\n",
      "StratifedKFold Score: 0.4600000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 52.000000 percent accurate\n",
      "Accuracy score in each iteration: [0.45, 0.44, 0.5, 0.39, 0.5]\n",
      "StratifedKFold Score: 0.45600000000000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 52.000000 percent accurate\n",
      "KNN is 50.000000 percent accurate\n",
      "Naive Bayes is 2.000000 percent accurate\n",
      "Linear SVMs is 52.000000 percent accurate\n",
      "Non Linear SVMs is 49.000000 percent accurate\n",
      "Decision Trees is 49.000000 percent accurate\n",
      "Random Forests is 50.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.46, 0.49, 0.48, 0.53, 0.37]\n",
      "StratifedKFold Score: 0.466\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hospitalcost=pd.read_csv('../Lab 3 Extension/HospitalCosts/HospitalCosts.csv')\n",
    "hospitalcost.head()\n",
    "import numpy as np\n",
    "hospitalcost.isnull().sum()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "hospitalcost.dropna(inplace=True)\n",
    "hospitalcost.drop(['TOTCHG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.drop(['APRDRG'], axis=1, inplace=True)\n",
    "hospitalcost.head()\n",
    "hospitalcost.isna().sum()\n",
    "X = hospitalcost.drop(['LOS'], axis=1)\n",
    "Y = hospitalcost['LOS']\n",
    "hospitalcost.head()\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=0\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "scores = []\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"StratifedKFold Score: {}\".format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d670acca4543613bc71420ba3b408e5826bdc54b760740e8ce26eaf03bb45f97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
